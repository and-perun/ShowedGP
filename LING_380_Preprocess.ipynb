{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66852dbc-54cd-43a4-a8ba-16c409c7cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe8f0c-6267-428b-a1dd-a0dcb8bca514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base_path\n",
    "base_path = \"\"\n",
    "\n",
    "# Path to word frequencies\n",
    "freqs = pd.read_csv(os.path.join(base_path, \"freqs_coca.csv\"), header=0)\n",
    "\n",
    "# Path to GP and filler files containing surprisal data for each word\n",
    "GP_base      = \"items_ClassicGP.ambig.csv.m\"\n",
    "filler_base  = \"items_filler.ambig.csv.m\"\n",
    "\n",
    "# Path to filler and GP reading times\n",
    "GP_RT_df     = pd.read_csv(os.path.join(base_path, \"ClassicGardenPathSet.csv\"), header=0)\n",
    "filler_RT_df = pd.read_csv(os.path.join(base_path, \"Fillers.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cfa5fe-b127-4622-bfb8-3277f7b4cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save df to file_path in chunks of size sz\n",
    "def save_progbar(df, file_path, sz=100000):\n",
    "    num_chunk = (len(df) // sz) + 1\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        # append header first\n",
    "        df.iloc[:0].to_csv(file, index=False)\n",
    "\n",
    "        # write rest of columns\n",
    "        for i in tqdm(range(num_chunk), desc=f\"Saving {file_path}\"):\n",
    "            start = i * sz\n",
    "            end = (i + 1) * sz\n",
    "            df.iloc[start:end].to_csv(file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0801721-b1ae-4826-b1f4-5755dd68b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "\n",
    "GP_paths     = [os.path.join(base_path, GP_base + str(n))  for n in range(4)]\n",
    "filler_paths = [os.path.join(base_path, filler_base + str(n)) for n in range(4)]\n",
    "\n",
    "GP_surp_dfs     = [pd.read_csv(filepath, header=0) for filepath in GP_paths]\n",
    "filler_surp_dfs = [pd.read_csv(filepath, header=0) for filepath in filler_paths]\n",
    "\n",
    "for n in range(len(filler_surp_dfs)):\n",
    "  filler_surp_dfs[n]['model'] = 'm' + str(n)\n",
    "  GP_surp_dfs[n]['model'] = 'm' + str(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4709a6-fb4b-40e2-8237-643779a627c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = GP_RT_df[(GP_RT_df['RT'] < 3000) & (GP_RT_df['RT'] > 0)]\n",
    "spr['Sentence'] = spr['Sentence'].str.replace('%2C', ',')\n",
    "spr['EachWord'] = spr['EachWord'].str.replace('%2C', ',')\n",
    "\n",
    "fspr = filler_RT_df[(filler_RT_df['RT'] < 3000) & (filler_RT_df['RT'] > 0)]\n",
    "fspr['Sentence'] = fspr['Sentence'].str.replace('%2C', ',')\n",
    "fspr['EachWord'] = fspr['EachWord'].str.replace('%2C', ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5eeb-14e4-4332-a2b6-672c3c568b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbound = pd.concat(filler_surp_dfs)\n",
    "fbound['word_clean'] = fbound['word'].str.lower().str.replace(\"[.,!?:;]'\", '', regex=True)\n",
    "fbound = fbound.merge(freqs, left_on=\"word_clean\", right_on=\"word\", how=\"left\")\n",
    "fbound['word_pos'] = fbound['word_pos'] + 1\n",
    "fmerged = pd.merge(fspr, fbound, left_on=['Sentence', 'WordPosition'], right_on=['Sentence', 'word_pos'], how='left')\n",
    "fmerged = fmerged.dropna(subset=['word_x'])\n",
    "fmerged['count'] = fmerged['count'].fillna(1)\n",
    "fmerged['logfreq'] = np.log(fmerged['count'])\n",
    "fmerged['length'] = fmerged['word_clean'].str.len()\n",
    "print(list(fmerged['EachWord'])[0:20])\n",
    "print(list(fmerged['word_x'])[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773555e-645d-4087-a49e-0be226194508",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = pd.concat(GP_surp_dfs)\n",
    "\n",
    "bound_long = bound.melt(id_vars=[col for col in bound.columns if col not in [\"sum_lex_surprisal\", \"sum_syn_surprisal\", \"mean_lex_surprisal\", \"mean_syn_surprisal\"]],\n",
    "                        value_vars=[\"sum_lex_surprisal\", \"sum_syn_surprisal\", \"mean_lex_surprisal\", \"mean_syn_surprisal\"],\n",
    "                        var_name=\"surprisal_type\", value_name=\"surprisal\")\n",
    "bound_long['word_pos_ralign'] = bound_long['word_pos'] - bound_long['disambPosition_0idx']\n",
    "\n",
    "\n",
    "bound['word_clean'] = bound['word'].str.lower().str.replace('[.,!?:;]', '', regex=True)\n",
    "merged = bound.merge(freqs, left_on=\"word_clean\", right_on=\"word\", how=\"left\")\n",
    "merged['word_pos'] = merged['word_pos'] + 1\n",
    "merged = pd.merge(spr, merged, left_on=['Sentence', 'WordPosition'], right_on=['Sentence', 'word_pos'], how='left')\n",
    "merged = merged.dropna(subset=['word_x'])\n",
    "merged['count'] = merged['count'].fillna(1)\n",
    "merged['logfreq'] = np.log(merged['count'])\n",
    "merged['length'] = merged['word_clean'].str.len()\n",
    "\n",
    "print(list(merged['EachWord'])[0:20])\n",
    "print(list(merged['word_x'])[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a365024-a724-4309-8805-cd784a4495c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: ensure lfreq_mean and np.std(lfreqs) are not NaN, as {f}merged['logfreq_s'] will regress to non-numerical values\n",
    "# Might have to precision of lfreq_mean and np.std(lfreqs) so as to not cause errors, or replace manually with decimals in code\n",
    "syn_surps = list(fmerged['sum_syn_surprisal']) + list(merged['sum_syn_surprisal'])\n",
    "lex_surps = list(fmerged['sum_lex_surprisal']) + list(merged['sum_lex_surprisal'])\n",
    "lengths = list(fmerged['length']) + list(merged['length'])\n",
    "lfreqs = list(fmerged['logfreq']) + list(merged['logfreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1806292-6cf6-4bd7-a831-30e41ff1ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_surp_mean = np.mean(syn_surps)\n",
    "lex_surp_mean = np.mean(lex_surps)\n",
    "len_mean = np.mean(lengths)\n",
    "lfreq_mean = np.mean(lfreqs)\n",
    "\n",
    "merged['syn_surprisal_s']  = (merged['sum_syn_surprisal']  - syn_surp_mean)/np.std(syn_surps)\n",
    "fmerged['syn_surprisal_s'] = (fmerged['sum_syn_surprisal'] - syn_surp_mean)/np.std(syn_surps)\n",
    "\n",
    "merged['lex_surprisal_s']  = (merged['sum_lex_surprisal']  - lex_surp_mean)/np.std(lex_surps)\n",
    "fmerged['lex_surprisal_s'] = (fmerged['sum_lex_surprisal'] - lex_surp_mean)/np.std(lex_surps)\n",
    "\n",
    "merged['length_s'] = (merged['length'] - len_mean)/np.std(lengths)\n",
    "fmerged['length_s'] = (fmerged['length'] - len_mean)/np.std(lengths)\n",
    "\n",
    "merged['logfreq_s'] = (merged['logfreq'] - lfreq_mean)/np.std(lfreqs)\n",
    "fmerged['logfreq_s'] = (fmerged['logfreq'] - lfreq_mean)/np.std(lfreqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e6c7f-126c-4e95-a693-ed741cd9dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmerged_file = f\"{base_path}/fmerged_mod.csv\"\n",
    "save_progbar(fmerged, fmerged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856c6ca-51a8-455c-9ff6-322d928475e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file = f\"{base_path}/merged_mod.csv\"\n",
    "save_progbar(merged, merged_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
